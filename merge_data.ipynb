{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the data for the R analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we merge the human subjects regressions/number of fixations with each model's revisions / number of edits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NA_VALUES = [\n",
    "    \"\", \"#N/A\", \"#N/A N/A\", \"#NA\", \"-1.#IND\", \"-1.#QNAN\", \"-NaN\", \n",
    "    \"-nan\", \"1.#IND\", \"1.#QNAN\", \"<NA>\", \"N/A\", \"NA\", \"NULL\", \"NaN\",\n",
    "    \"None\", \"n/a\", \"nan\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpora = ['rastros_ptbr', 'potec_de', 'provo_en', 'nicenboim_es', 'mecol1_du', 'mecol2_enl2']\n",
    "\n",
    "human_data = {tuple(name.split('_')): {} for name in corpora}\n",
    "\n",
    "# from https://stackoverflow.com/a/56469905\n",
    "with os.scandir('preprocessed/human_data/') as directory:\n",
    "    for entry in directory:\n",
    "        if entry.name.endswith('.tsv') and entry.is_file():\n",
    "            name, language, measure = entry.name.split('_')\n",
    "            df = pd.read_csv(entry.path, sep='\\t',\n",
    "                             # it is interpreting the token null as NaN, so we remove it from the defaulf list\n",
    "                             # to do that, we copy the default values without the null element\n",
    "                             keep_default_na=False,\n",
    "                             na_values=NA_VALUES)\n",
    "            df = df.drop('Unnamed: 0', axis=1)\n",
    "            df.set_index('Identifier', inplace=True)\n",
    "            df.sort_index(axis=0, inplace=True)\n",
    "            human_data[(name, language)][measure.removesuffix('.tsv')] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data = {tuple(name.split('_')): {'revisions': {}, 'edits': {}} for name in corpora}\n",
    "\n",
    "# from https://stackoverflow.com/a/56469905\n",
    "with os.scandir('preprocessed/model_data/') as directory:\n",
    "    for entry in directory:\n",
    "        if entry.name.endswith('.tsv') and entry.is_file():\n",
    "            name, language, model, measure = entry.name.split('_')\n",
    "            measure = measure.removesuffix(('.tsv'))\n",
    "            df = pd.read_csv(entry.path, sep='\\t',\n",
    "                             keep_default_na=False,\n",
    "                             na_values=NA_VALUES)\n",
    "            df.set_index('Unnamed: 0', inplace=True)\n",
    "            df.index.name = 'Identifier'\n",
    "            df.sort_index(axis=0, inplace=True)\n",
    "            columns = {name: f'{name}_{model}' for name in df.columns if 'revision' in name or 'edit' in name}\n",
    "            df.rename(columns=columns, inplace=True)\n",
    "            model_data[(name, language)][measure][model.removesuffix('.tsv')] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Revisions and regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MEASURE = 'first-pass-regression-out'\n",
    "MODEL_MEASURE = 'revisions'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for corpus_name in corpora:\n",
    "    key = tuple(corpus_name.split('_'))\n",
    "    ref_index = human_data[key][MEASURE].index\n",
    "    ref_tokens = human_data[key][MEASURE]['Token']\n",
    "    for dataframe in human_data[key].values():\n",
    "        assert all(dataframe.index == ref_index)\n",
    "        assert all(dataframe['Token'] == ref_tokens)\n",
    "        assert dataframe.Token.isna().sum() == 0\n",
    "\n",
    "    for model, dataframe in model_data[key][MODEL_MEASURE].items():\n",
    "        assert all(dataframe.index == ref_index)\n",
    "        assert dataframe.Token.isna().sum() == 0\n",
    "        if corpus_name == 'rastros_ptbr':\n",
    "            # we changed the space encoding and a quotation mark in 3 tokens\n",
    "            assert dataframe[dataframe['Token'] != ref_tokens].shape[0] == 3\n",
    "        elif corpus_name == 'potec_de':\n",
    "            # we changed the ; in 2 tokens\n",
    "            assert dataframe[dataframe['Token'] != ref_tokens].shape[0] == 2\n",
    "        else:\n",
    "            assert all(dataframe['Token'] == ref_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = {}\n",
    "\n",
    "for corpus_name in corpora:\n",
    "    corpus, lang = corpus_name.split('_')\n",
    "    if MEASURE not in human_data[(corpus, lang)]:\n",
    "        continue\n",
    "    aux = human_data[(corpus, lang)][MEASURE]\n",
    "\n",
    "    for model, data in model_data[(corpus, lang)][MODEL_MEASURE].items():\n",
    "        columns = [column for column in data.columns if 'revision' in column]\n",
    "        aux = aux.merge(data[columns], on='Identifier', suffixes=(\"\", '_' + model))\n",
    "    \n",
    "    merged[(corpus)] = aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rastros stanza-bilstm upos\n",
      "rastros stanza-bilstm deprel\n",
      "rastros stanza-bilstm head\n",
      "rastros hf-trf pos\n",
      "rastros hf-trf deprel\n",
      "rastros hf-trf head\n",
      "potec hf-trf pos\n",
      "potec hf-trf deprel\n",
      "potec hf-trf head\n",
      "potec stanza-bilstm upos\n",
      "potec stanza-bilstm xpos\n",
      "potec stanza-bilstm ner\n",
      "potec stanza-bilstm deprel\n",
      "potec stanza-bilstm head\n",
      "provo stanza-bilstm upos\n",
      "provo stanza-bilstm xpos\n",
      "provo stanza-bilstm ner\n",
      "provo stanza-bilstm deprel\n",
      "provo stanza-bilstm head\n",
      "provo hf-trf pos\n",
      "provo hf-trf deprel\n",
      "provo hf-trf head\n",
      "nicenboim hf-trf pos\n",
      "nicenboim hf-trf deprel\n",
      "nicenboim hf-trf head\n",
      "nicenboim stanza-bilstm upos\n",
      "nicenboim stanza-bilstm xpos\n",
      "nicenboim stanza-bilstm ner\n",
      "nicenboim stanza-bilstm deprel\n",
      "nicenboim stanza-bilstm head\n",
      "mecol1 stanza-bilstm upos\n",
      "mecol1 stanza-bilstm xpos\n",
      "mecol1 stanza-bilstm ner\n",
      "mecol1 stanza-bilstm deprel\n",
      "mecol1 stanza-bilstm head\n",
      "mecol1 hf-trf pos\n",
      "mecol1 hf-trf deprel\n",
      "mecol1 hf-trf head\n",
      "mecol2 hf-trf pos\n",
      "mecol2 hf-trf deprel\n",
      "mecol2 hf-trf head\n",
      "mecol2 stanza-bilstm upos\n",
      "mecol2 stanza-bilstm xpos\n",
      "mecol2 stanza-bilstm ner\n",
      "mecol2 stanza-bilstm deprel\n",
      "mecol2 stanza-bilstm head\n"
     ]
    }
   ],
   "source": [
    "for corpus, data in merged.items():\n",
    "    # plain revisions columns\n",
    "    model_cols = [c for c in data.columns if 'Subj' not in c and 'effective' not in c and 'convenient' not in c and 'Token' not in c]\n",
    "    # other columns\n",
    "    default_cols = [c for c in data.columns if 'revision' not in c]\n",
    "    # we will generate one dataframe for each column (i.e., each model+task)\n",
    "    for col in model_cols:\n",
    "        aux_data = data[[c for c in data.columns if c in default_cols or c == col]].copy()\n",
    "        # keep only subject identifier\n",
    "        aux_data.rename(columns={c: c.split(':')[1] for c in aux_data.columns if c not in (col, 'Token')}, inplace=True)\n",
    "        # standard name for the dependent variable\n",
    "        aux_data.rename(columns={col: 'revision'}, inplace=True)\n",
    "        task, model = col.replace('revision:', '').split('_')\n",
    "        if 'large' in task or 'chunk' in task:\n",
    "            task = task.split('-')[0]\n",
    "        aux_data = aux_data.reset_index()\n",
    "        \n",
    "        # put dataframe into R-friendly format (one human observation per row, with the dependent variable repeated for all subjects)\n",
    "        aux_data = aux_data.melt(id_vars=['Identifier', 'Token', 'revision'], value_name='regression', var_name='subjectid')\n",
    "        # split identifier into two columns with text id and token position\n",
    "        aux_data[['n1', 'textid', 'n2', 'token_position']] = aux_data['Identifier'].str.split('_', expand=True)\n",
    "        aux_data.drop('n1', axis=1, inplace=True)\n",
    "        aux_data.drop('n2', axis=1, inplace=True)\n",
    "        print(corpus, model, task)\n",
    "        aux_data.to_csv(f\"preprocessed/models-humans/revisions-regressions/{corpus}_{model}_{task}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effective revisions and regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rastros stanza-bilstm upos\n",
      "rastros stanza-bilstm deprel\n",
      "rastros stanza-bilstm head\n",
      "rastros hf-trf pos\n",
      "rastros hf-trf deprel\n",
      "rastros hf-trf head\n",
      "potec hf-trf pos\n",
      "potec hf-trf deprel\n",
      "potec hf-trf head\n",
      "potec stanza-bilstm upos\n",
      "potec stanza-bilstm xpos\n",
      "potec stanza-bilstm ner\n",
      "potec stanza-bilstm deprel\n",
      "potec stanza-bilstm head\n",
      "provo stanza-bilstm upos\n",
      "provo stanza-bilstm xpos\n",
      "provo stanza-bilstm ner\n",
      "provo stanza-bilstm deprel\n",
      "provo stanza-bilstm head\n",
      "provo hf-trf pos\n",
      "provo hf-trf deprel\n",
      "provo hf-trf head\n",
      "nicenboim hf-trf pos\n",
      "nicenboim hf-trf deprel\n",
      "nicenboim hf-trf head\n",
      "nicenboim stanza-bilstm upos\n",
      "nicenboim stanza-bilstm xpos\n",
      "nicenboim stanza-bilstm ner\n",
      "nicenboim stanza-bilstm deprel\n",
      "nicenboim stanza-bilstm head\n",
      "mecol1 stanza-bilstm upos\n",
      "mecol1 stanza-bilstm xpos\n",
      "mecol1 stanza-bilstm ner\n",
      "mecol1 stanza-bilstm deprel\n",
      "mecol1 stanza-bilstm head\n",
      "mecol1 hf-trf pos\n",
      "mecol1 hf-trf deprel\n",
      "mecol1 hf-trf head\n",
      "mecol2 hf-trf pos\n",
      "mecol2 hf-trf deprel\n",
      "mecol2 hf-trf head\n",
      "mecol2 stanza-bilstm upos\n",
      "mecol2 stanza-bilstm xpos\n",
      "mecol2 stanza-bilstm ner\n",
      "mecol2 stanza-bilstm deprel\n",
      "mecol2 stanza-bilstm head\n"
     ]
    }
   ],
   "source": [
    "for corpus, data in merged.items():\n",
    "    model_cols = [c for c in data.columns if 'effective' in c]\n",
    "    default_cols = [c for c in data.columns if 'revision' not in c]\n",
    "    for col in model_cols:\n",
    "        aux_data = data[[c for c in data.columns if c in default_cols or c == col]].copy()\n",
    "        aux_data.rename(columns={c: c.split(':')[1] for c in aux_data.columns if c not in (col, 'Token')}, inplace=True)\n",
    "        aux_data.rename(columns={col: 'revision'}, inplace=True)\n",
    "        task, model = col.replace('effective-revision:', '').split('_')\n",
    "        if 'large' in task or 'chunk' in task:\n",
    "            task = task.split('-')[0]\n",
    "        aux_data = aux_data.reset_index()\n",
    "        \n",
    "        aux_data = aux_data.melt(id_vars=['Identifier', 'Token', 'revision'], value_name='regression', var_name='subjectid')\n",
    "        \n",
    "        aux_data[['n1', 'textid', 'n2', 'token_position']] = aux_data['Identifier'].str.split('_', expand=True)\n",
    "        aux_data.drop('n1', axis=1, inplace=True)\n",
    "        aux_data.drop('n2', axis=1, inplace=True)\n",
    "        aux_data['revision'].fillna(0, inplace=True)\n",
    "        print(corpus, model, task)\n",
    "        aux_data.to_csv(f\"preprocessed/models-humans/effective_revisions-regressions/{corpus}_{model}_{task}.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "regressions",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
